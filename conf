import requests
from requests.auth import HTTPBasicAuth
import pandas as pd
import json
import urllib3
import os
from datetime import datetime
import logging
import re
from typing import Tuple, Optional, Dict, List

# -------------------------------------------------------------
# Confluence Publisher - Updated with Daily/Monthly Fixes
# -------------------------------------------------------------

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

MONTH_NAMES = (
    "January", "February", "March", "April", "May", "June",
    "July", "August", "September", "October", "November", "December"
)

# =============================================================
# Configuration / Auth
# =============================================================

def _is_monthly_run(config: Dict) -> bool:
    """Check if this is a monthly or daily run based on page title"""
    title = config.get('PAGE_TITLE', '')
    if title.endswith('_daily'):
        return False
    if re.search(r'\s-\s(' + '|'.join(MONTH_NAMES) + r'), title):
        return True
    return True  # default behave as monthly

def find_config_file(test_mode: bool = False) -> Optional[str]:
    """Find the config file in various possible locations."""
    if test_mode:
        search_paths = [
            "config/config_test.json",
            "config_test.json",
            "config/config.json",
            "config.json"
        ]
    else:
        search_paths = [
            "config/config.json",
            "config.json",
            "config/config_test.json",
            "config_test.json"
        ]
    
    for path in search_paths:
        abs_path = os.path.abspath(path)
        if os.path.exists(abs_path):
            logging.info(f"Found config file at: {abs_path}")
            return abs_path
    
    logging.error(f"Config file not found. Searched in: {search_paths}")
    return None

def load_config(config_path: str = None) -> Optional[Dict]:
    """Load configuration from the specified or auto-detected path."""
    try:
        if not config_path:
            config_path = find_config_file()
            if not config_path:
                logging.error("Could not find config file in any expected location")
                return None
        
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        required = ['CONFLUENCE_URL', 'USERNAME', 'SPACE_KEY', 'PAGE_TITLE']
        if not all(k in config for k in required):
            logging.error(f"Missing required configuration keys. Need: {required}")
            return None
        
        if 'BASELINE' not in config:
            config['BASELINE'] = 1899206
        
        logging.info(f"Successfully loaded config from {config_path}")
        return config
    except Exception as e:
        logging.error(f"Error loading config from {config_path}: {e}")
        return None

def get_password_from_config(config: Dict) -> Optional[str]:
    """Get password from config - either encrypted or base64 encoded."""
    if 'PASSWORD_ENCRYPTED' in config:
        try:
            from lib.secure_config import SecureConfig
            password = SecureConfig.decrypt_password(config['PASSWORD_ENCRYPTED'])
            if password:
                return password
        except Exception as e:
            logging.warning(f"Could not decrypt password: {e}")
    
    if 'PASSWORD_B64' in config:
        try:
            import base64
            password = base64.b64decode(config['PASSWORD_B64']).decode('utf-8')
            if password:
                return password
        except Exception as e:
            logging.warning(f"Could not decode base64 password: {e}")
    
    if 'PASSWORD' in config:
        return config['PASSWORD']
    
    return None

def create_session(config: Dict) -> Optional[requests.Session]:
    """Create authenticated session for Confluence API."""
    session = requests.Session()
    auth_type = config.get('AUTH_TYPE', 'basic').lower()
    
    if auth_type == 'basic':
        password = (os.environ.get('CONFLUENCE_PASSWORD') or
                    get_password_from_config(config) or
                    config.get('API_TOKEN'))
        
        if not password:
            logging.error("Missing credentials for basic auth.")
            return None
        
        session.auth = HTTPBasicAuth(config['USERNAME'], password)
        
    elif auth_type == 'jwt':
        token = os.environ.get('CONFLUENCE_TOKEN') or config.get('API_TOKEN')
        if not token:
            logging.error("Missing JWT token.")
            return None
        session.headers.update({"Authorization": f"Bearer {token}"})
        
    elif auth_type == 'cookie':
        cookie = os.environ.get('CONFLUENCE_COOKIE') or config.get('SESSION_COOKIE')
        if not cookie:
            logging.error("Missing cookie value for cookie auth.")
            return None
        session.headers.update({"Cookie": cookie})
    else:
        logging.error(f"Unsupported AUTH_TYPE {auth_type}")
        return None

    session.headers.update({
        "Content-Type": "application/json",
        "X-Atlassian-Token": "no-check"
    })
    
    if 'PROXY' in config:
        session.proxies = {"http": config['PROXY'], "https": config['PROXY']}
    
    session.verify = False
    return session

# =============================================================
# Data Loading & Sanitization
# =============================================================

def load_csv_data(csv_file: str) -> Tuple[pd.DataFrame, bool]:
    try:
        df = pd.read_csv(csv_file)
        if 'DATE' in df.columns:
            df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        return df, True
    except Exception as e:
        logging.error(f"Error loading CSV {csv_file}: {e}")
        return pd.DataFrame(), False

def sanitize_total_jobs(df: pd.DataFrame, preferred_col: Optional[str] = None) -> pd.DataFrame:
    """Ensure we have a numeric TOTAL_JOBS column."""
    candidate = None
    if preferred_col and preferred_col in df.columns:
        candidate = preferred_col
    elif 'TOTAL_JOBS' in df.columns:
        candidate = 'TOTAL_JOBS'
    else:
        for c in df.columns:
            if re.search(r'jobs|count|total', c.lower()):
                candidate = c
                break

    if candidate is None:
        logging.error("No suitable column found for TOTAL_JOBS.")
        df['TOTAL_JOBS'] = pd.Series(dtype='float')
        return df

    cleaned = (
        df[candidate]
        .astype(str)
        .str.replace(',', '', regex=False)
        .str.replace(' ', '', regex=False)
        .str.strip()
    )
    df['TOTAL_JOBS'] = pd.to_numeric(cleaned, errors='coerce')
    return df

# =============================================================
# Peak Calculation (Updated for Daily/Monthly)
# =============================================================

def compute_top_peaks_ytd(daily_df: pd.DataFrame, top_n: int = 4) -> pd.DataFrame:
    """Compute top N peaks for Year-To-Date (for daily reports)"""
    if daily_df.empty:
        return daily_df
    
    # Get current year
    current_year = datetime.now().year
    
    # Filter to current year
    ytd_df = daily_df[daily_df['DATE'].dt.year == current_year].copy()
    
    if ytd_df.empty:
        # Fallback to all data if no current year data
        ytd_df = daily_df.copy()
    
    # Get top N peaks by total jobs
    try:
        peaks = ytd_df.nlargest(top_n, 'TOTAL_JOBS')
    except Exception:
        peaks = ytd_df.sort_values('TOTAL_JOBS', ascending=False).head(top_n)
    
    return peaks[['DATE', 'TOTAL_JOBS']].sort_values('DATE')

def compute_top_peaks_monthly(daily_df: pd.DataFrame, top_n: int = 4) -> pd.DataFrame:
    """Compute top N peaks for the latest month (for monthly reports)"""
    if daily_df.empty:
        return daily_df
    
    # Get the latest month in the data
    latest_date = daily_df['DATE'].max()
    year = latest_date.year
    month = latest_date.month
    
    # Filter to that month
    month_df = daily_df[(daily_df['DATE'].dt.year == year) & 
                        (daily_df['DATE'].dt.month == month)].copy()
    
    if month_df.empty:
        return month_df
    
    # Get top N peaks
    try:
        peaks = month_df.nlargest(top_n, 'TOTAL_JOBS')
    except Exception:
        peaks = month_df.sort_values('TOTAL_JOBS', ascending=False).head(top_n)
    
    return peaks[['DATE', 'TOTAL_JOBS']].sort_values('DATE')

# =============================================================
# Chart Builders (Updated)
# =============================================================

def generate_jobs_data_table(df: pd.DataFrame, baseline: int, is_daily: bool = False) -> str:
    """
    Generate the Jobs Data table showing TOP 4 PEAKS with correct variance calculation.
    For daily: YTD top 4 peaks
    For monthly: Current month top 4 peaks
    Variance = Baseline - Total Jobs (positive when baseline is higher)
    """
    # Group by date and sum total jobs
    daily = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
    
    if daily.empty:
        return "<p>No daily data available.</p>"
    
    # Get top 4 peaks based on mode
    if is_daily:
        top_4_peaks = compute_top_peaks_ytd(daily, 4)
        title = "Jobs Data - Top 4 Peaks (YTD)"
    else:
        top_4_peaks = compute_top_peaks_monthly(daily, 4)
        title = "Jobs Data - Top 4 Peaks (Monthly)"
    
    if top_4_peaks.empty:
        return f"<p>No peak data available for {title}</p>"
    
    # Start the table
    html = f"""
<h3>{title}</h3>
<table class='wrapped'>
<tbody>
<tr>
    <th>Date</th>
    <th>Baseline</th>
    <th>Total Jobs</th>
    <th>Variation</th>
</tr>
"""
    
    # Add data rows
    for _, row in top_4_peaks.iterrows():
        date_str = row['DATE'].strftime('%m/%d/%Y')
        total_jobs = int(row['TOTAL_JOBS'])
        variation = baseline - total_jobs  # Correct calculation
        
        # Color coding - green when under baseline (positive variation), red when over (negative)
        if variation > 0:
            var_style = 'style="background-color:#90EE90;"'  # Light green
            var_text = f"{variation:,}"
        elif variation < 0:
            var_style = 'style="background-color:#FFB6C1;"'  # Light red  
            var_text = f"{abs(variation):,}"  # Show absolute value for display
        else:
            var_style = ''
            var_text = "0"
        
        html += f"""
<tr>
    <td>{date_str}</td>
    <td>{baseline:,}</td>
    <td>{total_jobs:,}</td>
    <td {var_style}>{var_text}</td>
</tr>
"""
    
    html += "</tbody></table>"
    return html

def generate_peaks_chart(peaks_df: pd.DataFrame, baseline: int, chart_title: str) -> str:
    """
    Create peaks chart with baseline comparison
    """
    if peaks_df.empty:
        return f"<p>No data for {chart_title}.</p>"
    
    # Sort by date
    peaks_df = peaks_df.sort_values('DATE')
    
    # Format dates
    date_format = peaks_df['DATE'].dt.strftime('%m/%d')
    
    # Build chart data table
    header_row = "<tr><th>Date</th>"
    for date in date_format:
        header_row += f"<th>{date}</th>"
    header_row += "</tr>"
    
    baseline_row = "<tr><td>Baseline</td>"
    for _ in range(len(peaks_df)):
        baseline_row += f"<td>{int(baseline)}</td>"
    baseline_row += "</tr>"
    
    jobs_row = "<tr><td>Total Jobs</td>"
    for _, row in peaks_df.iterrows():
        jobs_row += f"<td>{int(row['TOTAL_JOBS'])}</td>"
    jobs_row += "</tr>"
    
    return f"""
<ac:structured-macro ac:name="chart">
  <ac:parameter ac:name="title">{chart_title}</ac:parameter>
  <ac:parameter ac:name="type">bar</ac:parameter>
  <ac:parameter ac:name="orientation">vertical</ac:parameter>
  <ac:parameter ac:name="3D">true</ac:parameter>
  <ac:parameter ac:name="width">800</ac:parameter>
  <ac:parameter ac:name="height">400</ac:parameter>
  <ac:parameter ac:name="legend">true</ac:parameter>
  <ac:parameter ac:name="dataDisplay">true</ac:parameter>
  <ac:parameter ac:name="stacked">false</ac:parameter>
  <ac:parameter ac:name="showValues">true</ac:parameter>
  <ac:parameter ac:name="colors">#829A3D,#B83939</ac:parameter>
  <ac:rich-text-body>
    <table>
      <tbody>
        {header_row}
        {baseline_row}
        {jobs_row}
      </tbody>
    </table>
  </ac:rich-text-body>
</ac:structured-macro>
"""

def generate_monthly_usage_chart(df: pd.DataFrame, baseline: int) -> str:
    """
    Generate Overall Monthly Task Usage Report line chart (for all dates in dataset)
    Shows trend over time with baseline comparison
    """
    # Group by date and sum
    daily = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum().sort_values('DATE')
    
    if daily.empty:
        return "<p>No data for monthly usage chart.</p>"
    
    # Build the data table for the chart
    header_row = "<tr><th>Date</th>"
    for _, row in daily.iterrows():
        date_str = row['DATE'].strftime('%Y-%m-%d')
        header_row += f"<th>{date_str}</th>"
    header_row += "</tr>"
    
    # Baseline row
    baseline_row = "<tr><td>Baseline</td>"
    for _ in range(len(daily)):
        baseline_row += f"<td>{baseline}</td>"
    baseline_row += "</tr>"
    
    # Total Jobs row
    jobs_row = "<tr><td>Sum of TOTAL_JOBS</td>"
    for _, row in daily.iterrows():
        jobs_row += f"<td>{int(row['TOTAL_JOBS'])}</td>"
    jobs_row += "</tr>"
    
    return f"""
<h3>Overall Monthly Task Usage Report</h3>
<ac:structured-macro ac:name="chart">
  <ac:parameter ac:name="title">Overall Monthly Task Usage Report</ac:parameter>
  <ac:parameter ac:name="type">line</ac:parameter>
  <ac:parameter ac:name="width">1200</ac:parameter>
  <ac:parameter ac:name="height">400</ac:parameter>
  <ac:parameter ac:name="3D">false</ac:parameter>
  <ac:parameter ac:name="legend">true</ac:parameter>
  <ac:parameter ac:name="showValues">false</ac:parameter>
  <ac:parameter ac:name="colors">#829A3D,#B83939</ac:parameter>
  <ac:parameter ac:name="dataDisplay">after</ac:parameter>
  <ac:parameter ac:name="xLabel">Date</ac:parameter>
  <ac:parameter ac:name="yLabel">Jobs</ac:parameter>
  <ac:rich-text-body>
    <table>
      <tbody>
        {header_row}
        {baseline_row}
        {jobs_row}
      </tbody>
    </table>
  </ac:rich-text-body>
</ac:structured-macro>
"""

def generate_daily_total_chart(df: pd.DataFrame, baseline: int) -> str:
    """Generate daily totals bar chart"""
    daily = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum().sort_values('DATE')
    
    if daily.empty:
        return "<p>No daily data.</p>"
    
    # Create header row
    header_row = "<tr><th>Series</th>"
    for _, row in daily.iterrows():
        date_str = row['DATE'].strftime('%d-%m')
        header_row += f"<th>{date_str}</th>"
    header_row += "</tr>"
    
    # Create data row
    data_row = "<tr><td>Total Jobs</td>"
    for _, row in daily.iterrows():
        data_row += f"<td>{int(row['TOTAL_JOBS'])}</td>"
    data_row += "</tr>"
    
    table_html = f"""<table><tbody>{header_row}{data_row}</tbody></table>"""
    
    return f"""
<h3>Daily Total Jobs</h3>
<ac:structured-macro ac:name="chart">
  <ac:parameter ac:name="type">bar</ac:parameter>
  <ac:parameter ac:name="title">Daily Total Jobs</ac:parameter>
  <ac:parameter ac:name="width">1200</ac:parameter>
  <ac:parameter ac:name="height">600</ac:parameter>
  <ac:parameter ac:name="3D">true</ac:parameter>
  <ac:parameter ac:name="legend">false</ac:parameter>
  <ac:parameter ac:name="orientation">vertical</ac:parameter>
  <ac:parameter ac:name="labelAngle">90</ac:parameter>
  <ac:parameter ac:name="stacked">false</ac:parameter>
  <ac:parameter ac:name="showValues">true</ac:parameter>
  <ac:parameter ac:name="xaxisLabel">Date</ac:parameter>
  <ac:parameter ac:name="yaxisLabel">Jobs</ac:parameter>
  <ac:parameter ac:name="colors">#829A3D</ac:parameter>
  <ac:parameter ac:name="dataDisplay">after</ac:parameter>
  <ac:parameter ac:name="fontSize">10</ac:parameter>
  <ac:rich-text-body>
    {table_html}
  </ac:rich-text-body>
</ac:structured-macro>
"""

def generate_country_summary_chart(df: pd.DataFrame) -> str:
    """Generate bar chart showing total jobs per country"""
    country_col = None
    possible_country_cols = ['COUNTRY', 'Country', 'country', 'REGION', 'Region', 'region']
    
    for col in possible_country_cols:
        if col in df.columns:
            country_col = col
            break
    
    if country_col is None:
        return "<p>No country data available for country summary chart.</p>"
    
    country_totals = df.groupby(country_col, as_index=False)['TOTAL_JOBS'].sum()
    country_totals = country_totals.sort_values('TOTAL_JOBS', ascending=False)
    
    if country_totals.empty:
        return "<p>No country data available.</p>"
    
    # Create summary table
    table_html = f"""
<h4>Country Summary</h4>
<table class='wrapped'>
<tbody>
<tr>
    <th>Country/Market</th>
    <th>Total Jobs</th>
    <th>Percentage</th>
</tr>
"""
    
    total_all_jobs = country_totals['TOTAL_JOBS'].sum()
    
    for _, row in country_totals.iterrows():
        country = row[country_col]
        jobs = int(row['TOTAL_JOBS'])
        percentage = (jobs / total_all_jobs * 100) if total_all_jobs > 0 else 0
        table_html += f"""
<tr>
    <td>{country}</td>
    <td>{jobs:,}</td>
    <td>{percentage:.1f}%</td>
</tr>
"""
    
    table_html += "</tbody></table>"
    
    # Create chart data
    chart_header = "<tr><th>Country/Market</th><th>Task Count</th></tr>"
    chart_rows = []
    for _, row in country_totals.iterrows():
        country = row[country_col]
        jobs = int(row['TOTAL_JOBS'])
        chart_rows.append(f"<tr><td>{country}</td><td>{jobs}</td></tr>")
    
    chart_table_html = f"""<table><tbody>{chart_header}{''.join(chart_rows)}</tbody></table>"""
    
    chart = f"""
<h3>Total Jobs by Country</h3>
<ac:structured-macro ac:name="chart">
  <ac:parameter ac:name="type">bar</ac:parameter>
  <ac:parameter ac:name="title">Total Jobs by Country</ac:parameter>
  <ac:parameter ac:name="width">1200</ac:parameter>
  <ac:parameter ac:name="height">500</ac:parameter>
  <ac:parameter ac:name="3D">true</ac:parameter>
  <ac:parameter ac:name="legend">false</ac:parameter>
  <ac:parameter ac:name="orientation">vertical</ac:parameter>
  <ac:parameter ac:name="stacked">false</ac:parameter>
  <ac:parameter ac:name="showValues">true</ac:parameter>
  <ac:parameter ac:name="xaxisLabel">Country/Market</ac:parameter>
  <ac:parameter ac:name="yaxisLabel">Task Count</ac:parameter>
  <ac:parameter ac:name="colors">#829A3D</ac:parameter>
  <ac:parameter ac:name="dataDisplay">after</ac:parameter>
  <ac:parameter ac:name="labelAngle">45</ac:parameter>
  <ac:rich-text-body>
    {chart_table_html}
  </ac:rich-text-body>
</ac:structured-macro>
"""
    
    return table_html + chart

# =============================================================
# Confluence REST Helpers
# =============================================================

def get_page_info(session: requests.Session, config: Dict) -> Tuple[Optional[str], Optional[int]]:
    try:
        base_url = config['CONFLUENCE_URL'].rstrip('/')
        if not base_url.endswith('/content'):
            if base_url.endswith('/rest/api'):
                base_url = base_url + "/content"
            else:
                base_url = base_url + "/rest/api/content"
        
        params = {
            'title': config['PAGE_TITLE'],
            'spaceKey': config['SPACE_KEY'],
            'expand': 'version'
        }
        resp = session.get(base_url, params=params)
        
        if resp.status_code != 200:
            alt = f"{base_url}/search?cql=space={config['SPACE_KEY']} AND title=\"{config['PAGE_TITLE']}\""
            resp = session.get(alt)
        
        if resp.status_code != 200:
            logging.error(f"Page lookup failed: {resp.status_code} - {resp.text}")
            return None, None
        
        data = resp.json()
        if 'results' in data and data.get('size', 0) > 0:
            return data['results'][0]['id'], data['results'][0]['version']['number']
        if isinstance(data, list) and data:
            return data[0]['id'], data[0]['version']['number']
        return None, None
    except Exception as e:
        logging.error(f"Error getting page info: {e}")
        return None, None

def create_or_update_page(session: requests.Session, config: Dict, content: str,
                          page_id: Optional[str] = None, version: Optional[int] = None) -> bool:
    try:
        base_url = config['CONFLUENCE_URL'].rstrip('/')
        if not base_url.endswith('/content'):
            if base_url.endswith('/rest/api'):
                base_url = base_url + "/content"
            else:
                base_url = base_url + "/rest/api/content"
        
        payload = {
            "type": "page",
            "title": config['PAGE_TITLE'],
            "space": {"key": config['SPACE_KEY']},
            "body": {"storage": {"value": content, "representation": "storage"}}
        }
        
        if page_id and version is not None:
            payload["id"] = page_id
            payload["version"] = {"number": version + 1}
            resp = session.put(f"{base_url}/{page_id}", json=payload)
        else:
            resp = session.post(base_url, json=payload)
        
        if resp.status_code >= 400:
            logging.error(f"Create/Update failed: {resp.status_code} - {resp.text}")
            return False
        
        logging.info(f"Page '{config['PAGE_TITLE']}' {'updated' if page_id else 'created'} successfully.")
        return True
    except Exception as e:
        logging.error(f"Error creating/updating page: {e}")
        return False

def test_connection(session: requests.Session, config: Dict) -> bool:
    try:
        base = config['CONFLUENCE_URL'].rstrip('/')
        if base.endswith('/content'):
            base = base[:-8]
        elif not base.endswith('/rest/api'):
            base = base + '/rest/api'
        test_url = f"{base}/space"
        resp = session.get(test_url, params={'limit': 1})
        return resp.status_code == 200
    except Exception as e:
        logging.error(f"Connection test exception: {e}")
        return False

# =============================================================
# Main Publish Function
# =============================================================

def publish_to_confluence(report_file='task_usage_report_by_region.csv',
                          test_mode=False,
                          skip_actual_upload: bool = False) -> bool:
    """
    Publish report to Confluence with improved daily/monthly handling.
    """
    try:
        # Check report file exists
        if not os.path.exists(report_file):
            logging.error(f"Report file {report_file} not found.")
            return False
        
        # Find and load config
        cfg_path = find_config_file(test_mode)
        if not cfg_path:
            logging.error("Could not find config file")
            return False
        
        config = load_config(cfg_path)
        if not config:
            logging.error("Failed to load config")
            return False
        
        # Add test suffix if in test mode
        if test_mode and not config['PAGE_TITLE'].endswith("-TEST"):
            config['PAGE_TITLE'] += "-TEST"

        # Determine if this is monthly or daily run
        is_monthly = _is_monthly_run(config)
        is_daily = not is_monthly
        baseline = config.get('BASELINE', 1899206)

        # Load and sanitize data
        df, ok = load_csv_data(report_file)
        if not ok:
            logging.error("Failed to load CSV data")
            return False
        
        df = sanitize_total_jobs(df, preferred_col=config.get('JOB_COLUMN'))

        # Create session if not skipping upload
        session = None
        if not skip_actual_upload:
            session = create_session(config)
            if not session:
                logging.error("Failed to create session")
                return False
            
            if not test_connection(session, config):
                logging.error("Connection test failed.")
                return False

        # Generate content sections based on mode
        if is_daily:
            # Daily report - YTD peaks
            title_suffix = " - YTD"
            daily_data = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
            peaks = compute_top_peaks_ytd(daily_data, 4)
            peaks_chart_title = "4th Peak of YTD"
        else:
            # Monthly report - current month peaks
            title_suffix = ""
            daily_data = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
            peaks = compute_top_peaks_monthly(daily_data, 4)
            latest_month = peaks['DATE'].dt.strftime('%B').iloc[0] if not peaks.empty else "Current Month"
            peaks_chart_title = f"Top 4 Peaks of {latest_month}"
        
        # Generate all content sections
        jobs_data_table = generate_jobs_data_table(df, baseline, is_daily)
        peaks_chart = generate_peaks_chart(peaks, baseline, peaks_chart_title) if not peaks.empty else ""
        monthly_usage_chart = generate_monthly_usage_chart(df, baseline)
        daily_chart = generate_daily_total_chart(df, baseline)
        country_chart = generate_country_summary_chart(df)

        # Create page content
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        user = os.environ.get('USER', 'automated')
        
        content = f"""
<h1>Task Usage Report{title_suffix}{' - TEST DATA' if test_mode else ''}</h1>
<p><strong>Last updated:</strong> {timestamp}</p>
<p><strong>Generated by:</strong> {user}</p>
{peaks_chart}
{jobs_data_table}
{monthly_usage_chart}
{daily_chart}
{country_chart}
<hr />
<p><em>Note: This report shows the task usage data{' (TEST MODE)' if test_mode else ''}.</em></p>
"""

        # Skip actual upload if requested
        if skip_actual_upload:
            logging.info("Skipping actual upload (simulation mode)")
            return True

        # Get page info and create/update
        page_id, version = get_page_info(session, config)
        return create_or_update_page(session, config, content, page_id, version)

    except Exception as e:
        logging.error(f"Error in publish_to_confluence: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return False
