import requests
from requests.auth import HTTPBasicAuth
import pandas as pd
import json
import urllib3
import os
from datetime import datetime
import logging
from typing import Tuple, Optional
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('confluence_update.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ConfluenceReporter:
    def __init__(self, config_path: str = "config.json"):
        self.config = self._load_config(config_path)
        self.session = self._create_session()
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
    def _load_config(self, config_path: str) -> dict:
        with open(config_path, 'r') as f:
            config = json.load(f)
        required_keys = ['CONFLUENCE_URL', 'USERNAME', 'API_TOKEN',
                        'SPACE_KEY', 'PAGE_TITLE', 'CSV_FILE']
        if not all(key in config for key in required_keys):
            raise ValueError(f"Missing required configuration keys. Required: {required_keys}")
        return config
        
    def _create_session(self) -> requests.Session:
        session = requests.Session()
        session.auth = HTTPBasicAuth(self.config['USERNAME'], self.config['API_TOKEN'])
        session.headers.update({
            "Content-Type": "application/json",
            "X-Atlassian-Token": "no-check"
        })
        session.verify = False
        return session
        
    def load_and_process_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        df = pd.read_csv(self.config['CSV_FILE'])
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df_grouped = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
        df_top4 = df_grouped.nlargest(4, 'TOTAL_JOBS')
        df_top4['Base Line'] = 1889206
        return df_top4, df
        
    def generate_table_and_chart(self, df: pd.DataFrame) -> str:
        table_rows = ["<tr><th>DATE</th><th>Baseline</th><th>Total Jobs</th></tr>"]
        for _, row in df.iterrows():
            table_rows.append(
                f"<tr><td>{row['DATE'].strftime('%Y-%m-%d')}</td><td>{row['Base Line']:,}</td><td>{row['TOTAL_JOBS']:,}</td></tr>"
            )
        return f"""
<ac:structured-macro ac:name="table-chart">
    <ac:parameter ac:name="type">column</ac:parameter>
    <ac:parameter ac:name="is3d">true</ac:parameter>
    <ac:parameter ac:name="title">4th Peak of the Month</ac:parameter>
    <ac:parameter ac:name="legend">true</ac:parameter>
    <ac:parameter ac:name="dataorientation">vertical</ac:parameter>
    <ac:parameter ac:name="columns">Baseline,Total Jobs</ac:parameter>
    <ac:rich-text-body>
        <table class="wrapped">
            <colgroup><col/><col/></colgroup>
            <tbody>{''.join(table_rows)}</tbody>
        </table>
    </ac:rich-text-body>
</ac:structured-macro>
"""

    def generate_region_chart(self, df: pd.DataFrame) -> str:
        if not {'DATE', 'REGION', 'TOTAL_JOBS'}.issubset(df.columns):
            return ""
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df['DATE'] = df['DATE'].dt.strftime('%Y-%m-%d')
        pivot_df = df.pivot_table(index='DATE', columns='REGION', values='TOTAL_JOBS', aggfunc='sum')
        table_rows = [f"<tr><th>DATE</th>{{''.join(f'<th>{col}</th>' for col in pivot_df.columns)}}</tr>"]
        for _, row in pivot_df.iterrows():
            cells = [f"<td>{row['DATE']}</td>"] + [f"<td>{int(row[col]):,}</td>" for col in pivot_df.columns]
            table_rows.append(f"<tr>{''.join(cells)}</tr>")
        return f"""
<ac:structured-macro ac:name="table-chart">
    <ac:parameter ac:name="type">column</ac:parameter>
    <ac:parameter ac:name="is3d">true</ac:parameter>
    <ac:parameter ac:name="title">Total Jobs by Region per Date</ac:parameter>
    <ac:parameter ac:name="legend">true</ac:parameter>
    <ac:parameter ac:name="dataorientation">vertical</ac:parameter>
    <ac:rich-text-body>
        <table class="wrapped">
            <colgroup>{''.join(f'<col/>' for _ in pivot_df.columns)}</colgroup>
            <tbody>{''.join(table_rows)}</tbody>
        </table>
    </ac:rich-text-body>
</ac:structured-macro>
"""

    def generate_daily_summary_table(self, df: pd.DataFrame) -> str:
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df_summary = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
        df_summary['DATE'] = df_summary['DATE'].dt.strftime('%Y-%m-%d')
        rows = ["<tr><th>Date</th><th>Sum of TOTAL_JOBS</th></tr>"]
        for _, row in df_summary.iterrows():
            rows.append(f"<tr><td>{row['DATE']}</td><td>{int(row['TOTAL_JOBS']):,}</td></tr>")
        return f"<h2>Total Jobs Per Day</h2><table class='wrapped'><tbody>{''.join(rows)}</tbody></table>"

    def generate_daily_trend_chart(self, df: pd.DataFrame) -> str:
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df_summary = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
        df_summary['DATE'] = df_summary['DATE'].dt.strftime('%Y-%m-%d')
        rows = ["<tr><th>Date</th><th>Peaks</th></tr>"]
        for _, row in df_summary.iterrows():
            rows.append(f"<tr><td>{row['DATE']}</td><td>{int(row['TOTAL_JOBS'])}</td></tr>")
        return f"""
<ac:structured-macro ac:name="table-chart">
    <ac:parameter ac:name="type">timeLine</ac:parameter>
    <ac:parameter ac:name="is3d">false</ac:parameter>
    <ac:parameter ac:name="title">Daily Job Volume Trend</ac:parameter>
    <ac:parameter ac:name="legend">false</ac:parameter>
    <ac:parameter ac:name="dataorientation">vertical</ac:parameter>
    <ac:parameter ac:name="columns">Peaks</ac:parameter>
    <ac:rich-text-body>
        <table class="wrapped">
            <colgroup><col/><col/></colgroup>
            <tbody>{''.join(rows)}</tbody>
        </table>
    </ac:rich-text-body>
</ac:structured-macro>
"""

    def generate_peaks_variation_table(self, df: pd.DataFrame) -> str:
        baseline = 1899206
        max_range = 2000000
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df_summary = df.groupby('DATE', as_index=False)['TOTAL_JOBS'].sum()
        df_summary['DATE'] = df_summary['DATE'].dt.strftime('%Y-%m-%d')
        df_summary['Baseline'] = baseline
        df_summary['Max Range'] = max_range
        df_summary['Variation'] = df_summary['Baseline'] - df_summary['TOTAL_JOBS']
        rows = ["<tr><th>Date</th><th>Peaks</th><th>Variation with Baseline</th><th>Baseline</th></tr>"]
        for _, row in df_summary.iterrows():
            rows.append(f"<tr><td>{row['DATE']}</td><td>{int(row['TOTAL_JOBS']):,}</td><td>{int(row['Variation']):,}</td><td>{int(row['Baseline']):,}</td></tr>")
        return f"<h2>Daily Peaks vs Baseline</h2><table class='wrapped'><tbody>{''.join(rows)}</tbody></table>"

    def generate_market_share_chart(self, df: pd.DataFrame) -> str:
        if not {'Country/Market', 'TaskCount'}.issubset(df.columns):
            return ""
        df_market = df.groupby('Country/Market', as_index=False)['TaskCount'].sum().sort_values(by='TaskCount', ascending=False)
        rows = ["<tr><th>Country/Market</th><th>TaskCount</th></tr>"]
        for _, row in df_market.iterrows():
            rows.append(f"<tr><td>{row['Country/Market']}</td><td>{int(row['TaskCount']):,}</td></tr>")
        return f"""
<ac:structured-macro ac:name="table-chart">
    <ac:parameter ac:name="type">column</ac:parameter>
    <ac:parameter ac:name="is3d">false</ac:parameter>
    <ac:parameter ac:name="title">Task Count by Country/Market</ac:parameter>
    <ac:parameter ac:name="legend">false</ac:parameter>
    <ac:parameter ac:name="dataorientation">vertical</ac:parameter>
    <ac:rich-text-body>
        <table class="wrapped">
            <colgroup><col/><col/></colgroup>
            <tbody>{''.join(rows)}</tbody>
        </table>
    </ac:rich-text-body>
</ac:structured-macro>
"""

    def generate_market_share_table(self, df: pd.DataFrame) -> str:
        if not {'Country/Market', 'TaskCount'}.issubset(df.columns):
            return ""
        df_market = df.groupby('Country/Market', as_index=False)['TaskCount'].sum().sort_values(by='TaskCount', ascending=False)
        rows = ["<tr><th>Country/Market</th><th>Task Count</th></tr>"]
        for _, row in df_market.iterrows():
            rows.append(f"<tr><td>{row['Country/Market']}</td><td>{int(row['TaskCount']):,}</td></tr>")
        return f"<h2>Task Count by Country/Market (Raw Table)</h2><table class='wrapped'><tbody>{''.join(rows)}</tbody></table>"

    def run(self) -> None:
        df_top4, full_df = self.load_and_process_data()
        content = """
<h1>Overall Monthly Task Usage Report</h1>
<p><strong>Last updated:</strong> {now} UTC</p>
<p><strong>Generated by:</strong> {user}</p>
{table_and_chart}
{region_chart}
{daily_table}
{daily_trend_chart}
{peaks_variation_table}
{market_share_chart}
{market_share_table}
<hr/>
<p><em>Note: This report shows the top 4 dates with highest total jobs compared to baseline.</em></p>
""".format(
            now=datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
            user='satish537',  # Added your username here
            table_and_chart=self.generate_table_and_chart(df_top4),
            region_chart=self.generate_region_chart(full_df),
            daily_table=self.generate_daily_summary_table(full_df),
            daily_trend_chart=self.generate_daily_trend_chart(full_df),
            peaks_variation_table=self.generate_peaks_variation_table(full_df),
            market_share_chart=self.generate_market_share_chart(full_df),
            market_share_table=self.generate_market_share_table(full_df),
        )
        page_id, version = self.get_page_info()
        self.create_or_update_page(content, page_id, version)

    def get_page_info(self) -> Tuple[Optional[str], Optional[int]]:
        params = {
            'title': self.config['PAGE_TITLE'],
            'spaceKey': self.config['SPACE_KEY'],
            'expand': 'version'
        }
        response = self.session.get(self.config['CONFLUENCE_URL'], params=params)
        response.raise_for_status()
        data = response.json()
        if data['size'] > 0:
            return data['results'][0]['id'], data['results'][0]['version']['number']
        return None, None

    def create_or_update_page(self, content: str, page_id: Optional[str] = None, version: Optional[int] = None):
        payload = {
            "type": "page",
            "title": self.config['PAGE_TITLE'],
            "space": {"key": self.config['SPACE_KEY']},
            "body": {"storage": {"value": content, "representation": "storage"}}
        }
        if page_id:
            payload["id"] = page_id
            payload["version"] = {"number": version + 1}
            response = self.session.put(f"{self.config['CONFLUENCE_URL']}/{page_id}", json=payload)
        else:
            response = self.session.post(self.config['CONFLUENCE_URL'], json=payload)
        response.raise_for_status()
        logger.info(f"Page [{self.config['PAGE_TITLE']}] {'updated' if page_id else 'created'} successfully")

def main():
    try:
        reporter = ConfluenceReporter()
        reporter.run()
    except Exception as e:
        logger.error(f"Fatal error: {str(e)}")
        raise

if __name__ == "__main__":
    main()
